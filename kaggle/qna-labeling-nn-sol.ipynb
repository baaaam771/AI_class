{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport keras\nimport keras.backend as K\nfrom keras.layers import *\nfrom keras.callbacks import *\nfrom keras.optimizers import *\nfrom keras import Model\n\nimport pickle    \nimport os","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/google-quest-challenge/train.csv')\ntest = pd.read_csv('/kaggle/input/google-quest-challenge/test.csv')\nsubmission = pd.read_csv('/kaggle/input/google-quest-challenge/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"module_url = \"/kaggle/input/universalsentenceencoderlarge4/\"\nembed = hub.load(module_url)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def UniversalEmbedding(x):\n    results = embed(tf.squeeze(tf.cast(x, tf.string)))[\"outputs\"]\n    print(results)\n    return keras.backend.concatenate([results])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"targets = [\n        'question_asker_intent_understanding',\n        'question_body_critical',\n        'question_conversational',\n        'question_expect_short_answer',\n        'question_fact_seeking',\n        'question_has_commonly_accepted_answer',\n        'question_interestingness_others',\n        'question_interestingness_self',\n        'question_multi_intent',\n        'question_not_really_a_question',\n        'question_opinion_seeking',\n        'question_type_choice',\n        'question_type_compare',\n        'question_type_consequence',\n        'question_type_definition',\n        'question_type_entity',\n        'question_type_instructions',\n        'question_type_procedure',\n        'question_type_reason_explanation',\n        'question_type_spelling',\n        'question_well_written',\n        'answer_helpful',\n        'answer_level_of_information',\n        'answer_plausible',\n        'answer_relevance',\n        'answer_satisfaction',\n        'answer_type_instructions',\n        'answer_type_procedure',\n        'answer_type_reason_explanation',\n        'answer_well_written'    \n    ]\n\ninput_columns = ['question_title','question_body','answer']\n\nX1 = train[input_columns[0]].values.tolist()\nX2 = train[input_columns[1]].values.tolist()\nX3 = train[input_columns[2]].values.tolist()\nX1 = [x.replace('?','.').replace('!','.') for x in X1]\nX2 = [x.replace('?','.').replace('!','.') for x in X2]\nX3 = [x.replace('?','.').replace('!','.') for x in X3]\n\nX = [X1,X2,X3]\ny = train[targets].values.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def swish(x):\n    return K.sigmoid(x) * x\n\nembed_size = 512 \n\ninput_text1 = Input(shape=(1,), dtype=tf.string)\nembedding1 = Lambda(UniversalEmbedding, output_shape=(embed_size,))(input_text1)\ninput_text2 = Input(shape=(1,), dtype=tf.string)\nembedding2 = Lambda(UniversalEmbedding, output_shape=(embed_size,))(input_text2)\ninput_text3 = Input(shape=(1,), dtype=tf.string)\nembedding3 = Lambda(UniversalEmbedding, output_shape=(embed_size,))(input_text3)\n\nx = Concatenate()([embedding1,embedding2,embedding3])\nx = Dense(256, activation=swish)(x)\nx = Dropout(0.4)(x)\nx = BatchNormalization()(x)\nx = Dense(64, activation=swish, kernel_regularizer=keras.regularizers.l2(0.001))(x)\nx = Dropout(0.4)(x)\nx = BatchNormalization()(x)\noutput = Dense(len(targets),activation='sigmoid',name='output')(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Model(inputs=[input_text1,input_text2,input_text3], outputs=[output])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n                              patience=2, min_lr=1e-7, verbose=1)\noptimizer = Adadelta()\n\nmodel.compile(optimizer=optimizer, loss='binary_crossentropy')\nmodel.fit(X, [y], epochs=20, validation_split=.1,batch_size=32,callbacks=[reduce_lr])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X1 = test[input_columns[0]].values.tolist()\nX2 = test[input_columns[1]].values.tolist()\nX3 = test[input_columns[2]].values.tolist()\nX1 = [x.replace('?','.').replace('!','.') for x in X1]\nX2 = [x.replace('?','.').replace('!','.') for x in X2]\nX3 = [x.replace('?','.').replace('!','.') for x in X3]\n\npred_X = [X1,X2,X3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_y = model.predict(pred_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('/kaggle/input/google-quest-challenge/sample_submission.csv')\nsubmission[targets] = pred_y\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv(\"submission.csv\", index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}