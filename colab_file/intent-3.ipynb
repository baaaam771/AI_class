{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "intent",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9u9rzL83Ie3T"
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 데이터 분석에 불필요한 정보 제거\n",
        "def normalizeString(s):\n",
        "    hangul = re.compile('[^ ㄱ-ㅣ가-힣 ^☆; ^a-zA-Z~.!?]+')\n",
        "    match = hangul.search(s)\n",
        "\n",
        "    result = []\n",
        "\n",
        "    if not match:\n",
        "        result = hangul.sub('', s)\n",
        "\n",
        "    return result\n",
        "\n",
        "def preprocess_data(data_path):\n",
        "    with open(data_path, 'r', encoding='utf-8') as f:\n",
        "        lines = f.read().split('\\n')\n",
        "\n",
        "    input_texts = []\n",
        "    train_labels = []\n",
        "    input_chars = set()\n",
        "\n",
        "    with open(data_path, 'r', encoding='utf-8') as f:\n",
        "        lines = f.read().split('\\n')\n",
        "\n",
        "    for line in lines[:2500]:\n",
        "        tmp_text = line.split('\\t')\n",
        "\n",
        "        if len(tmp_text) > 1:\n",
        "            input_text = normalizeString(tmp_text[0])\n",
        "            target_label = tmp_text[1]\n",
        "\n",
        "        if len(input_text) > 0 and len(target_label) > 0:\n",
        "            input_texts.append(input_text)\n",
        "            train_labels.append(target_label)\n",
        "            for char in input_text:\n",
        "                if char not in input_chars:\n",
        "                    input_chars.add(char)\n",
        "\n",
        "    input_chars = sorted(list(input_chars))\n",
        "    num_input_tokens = len(input_chars)\n",
        "    num_sequence = max([len(txt) for txt in input_texts])\n",
        "\n",
        "    print('Number of samples:', len(input_texts))\n",
        "    print('Number of unique input tokens:', num_input_tokens)\n",
        "    print('Max sequence length for inputs:', num_sequence)\n",
        "\n",
        "    input_token_index = dict(\n",
        "        [(char, i) for i, char in enumerate(input_chars)])\n",
        "\n",
        "    train_data = np.zeros((len(input_texts),\n",
        "                           num_sequence),\n",
        "                          dtype='float32')\n",
        "\n",
        "    for i, input_text in enumerate(input_texts):\n",
        "        for t, char in enumerate(input_text):\n",
        "            train_data[i, t] = input_token_index[char]\n",
        "\n",
        "    train_labels = to_categorical(train_labels)\n",
        "\n",
        "    return train_data, train_labels, num_sequence, num_input_tokens, input_token_index"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTBwND9ZJm-f",
        "outputId": "9946788c-f892-4086-d034-3f6fdca5cf05"
      },
      "source": [
        "data_path = '/content/drive/MyDrive/Colab Notebooks/train_data.csv'\n",
        "train_data, train_labels, num_sequence, num_input_tokens, input_token_index = preprocess_data(data_path)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples: 2452\n",
            "Number of unique input tokens: 91\n",
            "Max sequence length for inputs: 15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5j35ABpNCO7"
      },
      "source": [
        "import json\n",
        "\n",
        "with open('./assets/input_token_index.json', 'w') as fp:\n",
        "  json.dump(input_token_index, fp)\n",
        "\n",
        "with open('./assets/model_parameter.json', 'w') as fp:\n",
        "  json.dump({\n",
        "      'num_input_tokens' : num_input_tokens,\n",
        "      'num_sequence' : num_sequence,\n",
        "      'embedding_dim' : 512\n",
        "  }, fp)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OVV69vYI23J"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "# 4개 분류\n",
        "model = Sequential([\n",
        "    layers.Embedding(num_input_tokens, 512, input_length=num_sequence),\n",
        "    layers.Conv1D(32, 2, activation='relu'),\n",
        "    layers.MaxPool1D(2),\n",
        "    layers.Conv1D(32, 2, activation='relu'),\n",
        "    layers.MaxPool1D(2),\n",
        "    layers.Conv1D(32, 2, activation='relu'),\n",
        "    layers.GlobalMaxPool1D(),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(4, activation='softmax')\n",
        "])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1sBXnoEJmbU"
      },
      "source": [
        "optimizer = RMSprop(lr=1e-4)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLyPv_d6OZy-"
      },
      "source": [
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['acc'])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEsDLhKjOhAR",
        "outputId": "6cf5353f-7c11-4a6c-9c79-c390e35ab772"
      },
      "source": [
        "model.fit(train_data, train_labels, epochs=20, batch_size=100, validation_split=0.2)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "20/20 [==============================] - 1s 32ms/step - loss: 1.3671 - acc: 0.4982 - val_loss: 1.3514 - val_acc: 0.5051\n",
            "Epoch 2/20\n",
            "20/20 [==============================] - 0s 21ms/step - loss: 1.3396 - acc: 0.5258 - val_loss: 1.3241 - val_acc: 0.5479\n",
            "Epoch 3/20\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.3111 - acc: 0.5645 - val_loss: 1.2932 - val_acc: 0.5703\n",
            "Epoch 4/20\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.2787 - acc: 0.5864 - val_loss: 1.2596 - val_acc: 0.5988\n",
            "Epoch 5/20\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.2435 - acc: 0.5931 - val_loss: 1.2213 - val_acc: 0.5988\n",
            "Epoch 6/20\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.2030 - acc: 0.5931 - val_loss: 1.1786 - val_acc: 0.5988\n",
            "Epoch 7/20\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.1584 - acc: 0.5931 - val_loss: 1.1323 - val_acc: 0.5988\n",
            "Epoch 8/20\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 1.1100 - acc: 0.5941 - val_loss: 1.0823 - val_acc: 0.5988\n",
            "Epoch 9/20\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 1.0566 - acc: 0.6124 - val_loss: 1.0262 - val_acc: 0.6069\n",
            "Epoch 10/20\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 0.9974 - acc: 0.6548 - val_loss: 0.9671 - val_acc: 0.6619\n",
            "Epoch 11/20\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 0.9340 - acc: 0.7068 - val_loss: 0.9033 - val_acc: 0.6925\n",
            "Epoch 12/20\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 0.8678 - acc: 0.7430 - val_loss: 0.8394 - val_acc: 0.7332\n",
            "Epoch 13/20\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 0.7999 - acc: 0.7598 - val_loss: 0.7722 - val_acc: 0.7332\n",
            "Epoch 14/20\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 0.7297 - acc: 0.7598 - val_loss: 0.7032 - val_acc: 0.7332\n",
            "Epoch 15/20\n",
            "20/20 [==============================] - 0s 21ms/step - loss: 0.6576 - acc: 0.7639 - val_loss: 0.6346 - val_acc: 0.7515\n",
            "Epoch 16/20\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 0.5863 - acc: 0.7965 - val_loss: 0.5652 - val_acc: 0.7739\n",
            "Epoch 17/20\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 0.5182 - acc: 0.8628 - val_loss: 0.5007 - val_acc: 0.9430\n",
            "Epoch 18/20\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 0.4527 - acc: 0.9781 - val_loss: 0.4361 - val_acc: 1.0000\n",
            "Epoch 19/20\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 0.3896 - acc: 1.0000 - val_loss: 0.3745 - val_acc: 1.0000\n",
            "Epoch 20/20\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 0.3287 - acc: 1.0000 - val_loss: 0.3147 - val_acc: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5f1a785390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geKhy1MROrkc"
      },
      "source": [
        "model.save('./assets/intent_model.h5')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEJDOBDIPERz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}