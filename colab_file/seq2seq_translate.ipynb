{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "seq2seq_translate.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPDIzWhUs2Eq",
        "outputId": "7e4378cb-76fc-493d-9cd4-f426f05bd8ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget \"https://drive.google.com/uc?export=download&id=1rc_3n91So-S-zyoRh3JD9SoeJoU15TbM\" -O \"fra.txt\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-05 13:05:48--  https://drive.google.com/uc?export=download&id=1rc_3n91So-S-zyoRh3JD9SoeJoU15TbM\n",
            "Resolving drive.google.com (drive.google.com)... 74.125.23.101, 74.125.23.138, 74.125.23.100, ...\n",
            "Connecting to drive.google.com (drive.google.com)|74.125.23.101|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-14-94-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/ou6b9rnrsl603a07oesfb3h8799n7gaf/1604581500000/13472183013488020071/*/1rc_3n91So-S-zyoRh3JD9SoeJoU15TbM?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2020-11-05 13:05:49--  https://doc-14-94-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/ou6b9rnrsl603a07oesfb3h8799n7gaf/1604581500000/13472183013488020071/*/1rc_3n91So-S-zyoRh3JD9SoeJoU15TbM?e=download\n",
            "Resolving doc-14-94-docs.googleusercontent.com (doc-14-94-docs.googleusercontent.com)... 108.177.97.132, 2404:6800:4008:c00::84\n",
            "Connecting to doc-14-94-docs.googleusercontent.com (doc-14-94-docs.googleusercontent.com)|108.177.97.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/plain]\n",
            "Saving to: ‘fra.txt’\n",
            "\n",
            "fra.txt                 [  <=>               ]  11.33M  28.7MB/s    in 0.4s    \n",
            "\n",
            "2020-11-05 13:05:50 (28.7 MB/s) - ‘fra.txt’ saved [11876774]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsw8z1Lggm64"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unUWAYcfgm67"
      },
      "source": [
        "batch_size = 64      # 학습 배치 사이즈.\n",
        "epochs = 100         # 학습하고자 하는 에폭 사이즈.\n",
        "latent_dim = 256     # 인코더 디코더 LSTM 모델의 unit 사이즈.\n",
        "num_samples = 10000  # 입력 데이터의 최대 sequence.\n",
        "# 프랑스-영어 병렬 코퍼스 파일 경로.\n",
        "data_path = 'fra.txt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ll26R7xgm68"
      },
      "source": [
        "input_texts = []\n",
        "target_texts = []\n",
        "input_characters = set()\n",
        "target_characters = set()\n",
        "\n",
        "with open(data_path, 'r', encoding='utf-8') as f:\n",
        "    lines = f.read().split('\\n')\n",
        "\n",
        "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
        "    input_text, target_text = line.split('\\t')\n",
        "    # \"tab\"을 목표 데이터의 시작, 종료 문자로 지정\n",
        "    target_text = '\\t' + target_text + '\\n'\n",
        "    input_texts.append(input_text)\n",
        "    target_texts.append(target_text)\n",
        "    for char in input_text:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "    for char in target_text:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoNxZ7Bigm6-"
      },
      "source": [
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters))\n",
        "num_encoder_tokens = len(input_characters)\n",
        "num_decoder_tokens = len(target_characters)\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jb4nMo7gm6_",
        "outputId": "a2338c88-f0ab-4770-c624-5a3d62bc472e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('Number of samples:', len(input_texts))\n",
        "print('Number of unique input tokens:', num_encoder_tokens)\n",
        "print('Number of unique output tokens:', num_decoder_tokens)\n",
        "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
        "print('Max sequence length for outputs:', max_decoder_seq_length)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples: 10000\n",
            "Number of unique input tokens: 70\n",
            "Number of unique output tokens: 93\n",
            "Max sequence length for inputs: 16\n",
            "Max sequence length for outputs: 59\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bF_3R-rdgm7D"
      },
      "source": [
        "input_token_index = dict(\n",
        "    [(char, i) for i, char in enumerate(input_characters)])\n",
        "target_token_index = dict(\n",
        "    [(char, i) for i, char in enumerate(target_characters)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ue82Ocgsgm7E"
      },
      "source": [
        "encoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNo2Rt2Ggm7G"
      },
      "source": [
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
        "    for t, char in enumerate(target_text):\n",
        "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
        "        if t > 0:\n",
        "            # 디코더의 목표 데이터는 디코더 입력 데이터 보다 한 step 만큼 앞서 있음\n",
        "            # 또한 디코더의 목표 데이터는 시작 문자(tab) 이 존재하지 않음\n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGNSndfKgm7I"
      },
      "source": [
        "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
        "encoder = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "# 인코더의 결과 값 중 맥락벡터(h, c) 만 디코더 모델로 전달\n",
        "encoder_states = [state_h, state_c]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oo16VyGUgm7K"
      },
      "source": [
        "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
        "# 디코더의 상태값(h, c)값을 매 스텝마다 리턴 받도록 설정\n",
        "# 학습시에는 상태값을 사용하지 않지만 예측 시에 사용\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "# 인코더에서 계산 된 맥락벡터(h, c)를 디코더의 첫번째 은닉층의 상태값으로 사용\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
        "                                     initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doUsmVOQgm7N"
      },
      "source": [
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjmmGwVzgm7O",
        "outputId": "d037cb67-a9a3-414e-d160-c099ebe3f84d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "125/125 [==============================] - 48s 385ms/step - loss: 0.9110 - val_loss: 0.9360\n",
            "Epoch 2/100\n",
            "125/125 [==============================] - 47s 379ms/step - loss: 0.7222 - val_loss: 0.7581\n",
            "Epoch 3/100\n",
            "125/125 [==============================] - 47s 376ms/step - loss: 0.6145 - val_loss: 0.6750\n",
            "Epoch 4/100\n",
            "125/125 [==============================] - 48s 380ms/step - loss: 0.5596 - val_loss: 0.6276\n",
            "Epoch 5/100\n",
            "125/125 [==============================] - 48s 382ms/step - loss: 0.5205 - val_loss: 0.5979\n",
            "Epoch 6/100\n",
            "125/125 [==============================] - 48s 383ms/step - loss: 0.4889 - val_loss: 0.5663\n",
            "Epoch 7/100\n",
            "125/125 [==============================] - 47s 377ms/step - loss: 0.4630 - val_loss: 0.5451\n",
            "Epoch 8/100\n",
            "125/125 [==============================] - 48s 381ms/step - loss: 0.4410 - val_loss: 0.5235\n",
            "Epoch 9/100\n",
            "125/125 [==============================] - 47s 378ms/step - loss: 0.4221 - val_loss: 0.5105\n",
            "Epoch 10/100\n",
            "125/125 [==============================] - 48s 380ms/step - loss: 0.4049 - val_loss: 0.4973\n",
            "Epoch 11/100\n",
            "125/125 [==============================] - 47s 376ms/step - loss: 0.3893 - val_loss: 0.4901\n",
            "Epoch 12/100\n",
            "125/125 [==============================] - 52s 416ms/step - loss: 0.3742 - val_loss: 0.4783\n",
            "Epoch 13/100\n",
            "125/125 [==============================] - 47s 379ms/step - loss: 0.3606 - val_loss: 0.4805\n",
            "Epoch 14/100\n",
            "125/125 [==============================] - 47s 379ms/step - loss: 0.3480 - val_loss: 0.4676\n",
            "Epoch 15/100\n",
            "125/125 [==============================] - 47s 378ms/step - loss: 0.3357 - val_loss: 0.4609\n",
            "Epoch 16/100\n",
            "125/125 [==============================] - 47s 378ms/step - loss: 0.3242 - val_loss: 0.4597\n",
            "Epoch 17/100\n",
            "125/125 [==============================] - 48s 381ms/step - loss: 0.3136 - val_loss: 0.4564\n",
            "Epoch 18/100\n",
            "125/125 [==============================] - 48s 385ms/step - loss: 0.3034 - val_loss: 0.4548\n",
            "Epoch 19/100\n",
            "125/125 [==============================] - 48s 382ms/step - loss: 0.2934 - val_loss: 0.4542\n",
            "Epoch 20/100\n",
            "125/125 [==============================] - 48s 382ms/step - loss: 0.2843 - val_loss: 0.4543\n",
            "Epoch 21/100\n",
            "125/125 [==============================] - 47s 378ms/step - loss: 0.2749 - val_loss: 0.4498\n",
            "Epoch 22/100\n",
            "125/125 [==============================] - 48s 381ms/step - loss: 0.2667 - val_loss: 0.4561\n",
            "Epoch 23/100\n",
            "125/125 [==============================] - 47s 380ms/step - loss: 0.2583 - val_loss: 0.4510\n",
            "Epoch 24/100\n",
            "125/125 [==============================] - 48s 382ms/step - loss: 0.2501 - val_loss: 0.4565\n",
            "Epoch 25/100\n",
            "125/125 [==============================] - 48s 384ms/step - loss: 0.2426 - val_loss: 0.4538\n",
            "Epoch 26/100\n",
            "125/125 [==============================] - 47s 377ms/step - loss: 0.2353 - val_loss: 0.4555\n",
            "Epoch 27/100\n",
            "125/125 [==============================] - 47s 377ms/step - loss: 0.2285 - val_loss: 0.4588\n",
            "Epoch 28/100\n",
            "125/125 [==============================] - 48s 382ms/step - loss: 0.2215 - val_loss: 0.4623\n",
            "Epoch 29/100\n",
            "125/125 [==============================] - 48s 383ms/step - loss: 0.2155 - val_loss: 0.4669\n",
            "Epoch 30/100\n",
            "125/125 [==============================] - 48s 383ms/step - loss: 0.2096 - val_loss: 0.4696\n",
            "Epoch 31/100\n",
            "125/125 [==============================] - 52s 417ms/step - loss: 0.2033 - val_loss: 0.4721\n",
            "Epoch 32/100\n",
            "125/125 [==============================] - 48s 384ms/step - loss: 0.1980 - val_loss: 0.4784\n",
            "Epoch 33/100\n",
            "125/125 [==============================] - 47s 375ms/step - loss: 0.1921 - val_loss: 0.4770\n",
            "Epoch 34/100\n",
            "125/125 [==============================] - 47s 374ms/step - loss: 0.1874 - val_loss: 0.4838\n",
            "Epoch 35/100\n",
            "125/125 [==============================] - 47s 377ms/step - loss: 0.1823 - val_loss: 0.4914\n",
            "Epoch 36/100\n",
            "125/125 [==============================] - 47s 378ms/step - loss: 0.1776 - val_loss: 0.4901\n",
            "Epoch 37/100\n",
            "125/125 [==============================] - 48s 380ms/step - loss: 0.1727 - val_loss: 0.4989\n",
            "Epoch 38/100\n",
            "125/125 [==============================] - 48s 381ms/step - loss: 0.1680 - val_loss: 0.4956\n",
            "Epoch 39/100\n",
            "125/125 [==============================] - 48s 381ms/step - loss: 0.1639 - val_loss: 0.5011\n",
            "Epoch 40/100\n",
            "125/125 [==============================] - 47s 378ms/step - loss: 0.1599 - val_loss: 0.5046\n",
            "Epoch 41/100\n",
            "125/125 [==============================] - 47s 377ms/step - loss: 0.1558 - val_loss: 0.5113\n",
            "Epoch 42/100\n",
            "125/125 [==============================] - 47s 377ms/step - loss: 0.1519 - val_loss: 0.5121\n",
            "Epoch 43/100\n",
            "125/125 [==============================] - 47s 377ms/step - loss: 0.1483 - val_loss: 0.5230\n",
            "Epoch 44/100\n",
            "125/125 [==============================] - 47s 378ms/step - loss: 0.1444 - val_loss: 0.5210\n",
            "Epoch 45/100\n",
            "125/125 [==============================] - 48s 381ms/step - loss: 0.1410 - val_loss: 0.5386\n",
            "Epoch 46/100\n",
            "125/125 [==============================] - 47s 378ms/step - loss: 0.1377 - val_loss: 0.5333\n",
            "Epoch 47/100\n",
            "125/125 [==============================] - 47s 376ms/step - loss: 0.1342 - val_loss: 0.5382\n",
            "Epoch 48/100\n",
            "125/125 [==============================] - 47s 374ms/step - loss: 0.1315 - val_loss: 0.5402\n",
            "Epoch 49/100\n",
            " 95/125 [=====================>........] - ETA: 10s - loss: 0.1279"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdoI3h7Dgm7Q"
      },
      "source": [
        "model.save('s2s.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlZSw_5Ugm7S"
      },
      "source": [
        "encoder_model = Model(encoder_inputs, encoder_states)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0hR7zFIgm7T"
      },
      "source": [
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "    decoder_inputs, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs] + decoder_states)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3cB7cLCgm7V"
      },
      "source": [
        "reverse_input_char_index = dict(\n",
        "    (i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict(\n",
        "    (i, char) for char, i in target_token_index.items())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3FQe9pagm7X"
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # 인코더 모델에 입력 데이터를 넣어 상태값(h, c)을 계산\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # 디코더 모델에서 이전 스텝의 결과를 다음 스텝에 넣어주기 위한 변수 생성\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    # 디코더 모델에 최초 스텝에 입력되는 시작 문자(Tab) 설정\n",
        "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq] + states_value)\n",
        "\n",
        "        # 디코더에 의해 계산된 문자별 확률값에서 가장 높은 값의 인덱스를 가져옴\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        # 반복문의 종료 조건 체크(스텝의 학습데이터의 최대 사이즈를 넘어가는지\n",
        "        # , 종료 문자(Tab) 발생하는지)\n",
        "        if (sampled_char == '\\n' or\n",
        "           len(decoded_sentence) > max_decoder_seq_length):\n",
        "            stop_condition = True\n",
        "\n",
        "        # 디코더의 다음 스텝에 입력데이터로 사용할 문자값을 계산된 값으로 업데이트\n",
        "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.\n",
        "\n",
        "        # 디코더의 다음 스텝에 사용할 상테값을 계산된 값으로 업데이트\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyYZsO4agm7Z"
      },
      "source": [
        "for seq_index in range(100):\n",
        "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print('-')\n",
        "    print('Input sentence:', input_texts[seq_index])\n",
        "    print('Decoded sentence:', decoded_sentence)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPORCcz3gm7d"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ze6P_rj1gm7f"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOecq8yWgm7i"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}